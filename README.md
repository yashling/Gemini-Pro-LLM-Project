# Gemini-Pro-LLM-Project
🔍 AI-Powered Web Applications with Streamlit + Gemini Pro + Groq
This project showcases a suite of intelligent web applications built using Streamlit and powered by Google’s Gemini Pro, Groq, Gemma, and FAISS. Each app demonstrates the practical capabilities of LLMs across multiple modalities:

💬 Gemini Q&A Chatbot
A conversational app that uses Gemini 2.0 Flash to answer user queries and maintain chat history — ideal for dynamic, real-time interactions.

📄 PDF Q&A with Groq + Gemma + FAISS
Upload any PDF and ask questions in plain English. Uses FAISS for semantic search and combines Groq’s ultra-fast inference with Gemma’s language modeling for instant answers.

🧠 Text-to-SQL App
Turn natural language into database queries — no SQL knowledge required. This app dynamically builds an SQLite database and fetches accurate results using Gemini’s understanding.

🖼️ Vision-Based Q&A
Use Gemini 1.5 Flash to extract insights from images. Just upload a visual, add an optional prompt, and get contextual explanations.

🚀 Tech Stack
Streamlit – interactive web UI

Gemini Pro / Flash – language and vision models by Google

Groq – ultra-fast inference engine

Gemma – lightweight open-source LLM

FAISS (CPU) – vector search and semantic similarity

SQLite – backend database for text-to-SQL

Python, dotenv, PIL
